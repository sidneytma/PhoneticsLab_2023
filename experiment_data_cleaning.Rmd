# Experiment Data Cleaning
#### 10/24/23

After a participant runs through the experiment, their results are kept in a large Excel spreadsheet. In order to analyze the study results, Maxine needs this experiment data to be stacked into one long table.

Tasks:

* Select relevant columns from each spreadsheet
* Stack each spreadsheet into a long table
* Get the voice qualities
* Get the reaction times
* Return and save a cleaned dataset

## Combining datasets

```{r setup, include=FALSE}
library(tidyverse)
library(kableExtra)
```
```{r}
# Set up the directory - this will be different for Maxine
dir_name <- 'New data/'
```

Firstly, let's define a function that returns a dataset based on a given csv filename. Let's only select relevant columns.

```{r}
get_df <- function(filename) {
  relevant_cols <- c('word1', 'word2', 'target', 'voicequality', 'speaker', 
                     'time_to_target', 'response', 'audio', 'category', 
                     'key_resp.keys', 'key_resp.corr', 'key_resp.rt', 
                     'participant', 'date')
  df <- read.csv(filename)[,relevant_cols]
  df <- df[!is.na(df$key_resp.corr),]
  return(df)
}
```

Now, let's use this to make one giant dataset, combining all the relevant data from the New data folder.

```{r}
filenames <- list.files(dir_name, full.names = TRUE)
dfs <- lapply(filenames, get_df)
big_df <- bind_rows(dfs) |>
  arrange(participant)

kable(head(big_df), "html") |>
  kable_styling() |>
  scroll_box(width = "100%", height = "300px")
```

## Preparing the dataset

Now, let's do some of the manipulation task described above:

```{r}
# Set up voice quality columns
big_df$vq1 <- ifelse(is.na(big_df$voicequality), NA, substr(big_df$voicequality, 1, 1))
big_df$vq2 <- ifelse(is.na(big_df$voicequality), NA, substr(big_df$voicequality, 3, 3))

# Set up reaction time column
big_df$reaction_time <- big_df$key_resp.rt - big_df$time_to_target
big_df <- big_df |>
  select(-time_to_target, -key_resp.rt) |>
  rename(ppt_response = key_resp.keys, correct = key_resp.corr)

# Fix date column
big_df$date <- sapply(strsplit(big_df$date, "_"), `[`, 1)

# Reorder columns
reorder_cols <- c('category', 'word1', 'word2', 'target', 'ppt_response', 'voicequality', 'vq1', 
                  'vq2', 'correct', 'reaction_time', 'speaker', 'audio', 'participant', 'date')
big_df <- big_df[, reorder_cols]

# Add index column
big_df <- big_df |>
  mutate(index = row_number()) |>
  select(index, everything())

kable(head(big_df), "html") |>
  kable_styling() |>
  scroll_box(width = "100%", height = "300px")
```

## Saving the dataset

Now the dataset is complete, and can be saved to csv:

```{r}
# Save to CSV to CURRENT DIRECTORY
write.csv(big_df, 'ppt_data.csv', row.names = FALSE)
```

With this code, we should be able to combine and clean all participant data, as long as we have the directory.


